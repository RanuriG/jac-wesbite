[{"frontmatter":{"title":"Harnessing the Power of Generative AI: Insights and Use Cases from Jason Mars","description":"meta description","date":"2023-04-04T00:00:00.000Z","image":"/images/posts/post-1.png","categories":["AI + Business"],"authors":["Jaseci"],"tags":["AI + Business"],"draft":false},"content":"\nThis article is based on a talk by Jason Mars at the Michigan Technology Leaders Summit, presented by SIM Detroit, on the topic of Artificial Intelligence: Actual Use Cases.\n\n## What criteria do you use to prioritize AI projects in your portfolio and how often do you ensure alignment with broader business objectives?\n\nIn the last year, we’ve partnered with companies to bring two generative AI solutions to production, observing key drivers across multiple sectors. These drivers can be categorized into two main themes.\n\nFirstly, companies see AI as an opportunity to scale productivity, market output, and business efficiency. On the other hand, they perceive AI as a risk, navigating a new competitive landscape where survival depends on capitalizing on AI opportunities. This is particularly evident in the financial sector, where companies recognize the need to compete in a more efficient market.\n\nThe launch of ChatGPT marked a significant shift in the market, with VC investment in AI skyrocketing from $2 billion to $14 billion within six months. Companies realize that to survive, they need to compete in a higher efficiency landscape. This realization has led to a surge in market and internal capability analyses to identify the safest starting points for AI implementation.\n\n## Financial & Business Use Cases of Generative AI\n\nA notable trend is the democratization of AI, which has become a mandate rather than an option. Smaller, specialized models have emerged, offering cost-effective alternatives to large foundation models like GPT-4.\n\nFor example, we’ve worked with PocketNest, a Michigan-based company, to build a conversational AI focused on financial advice. By using smaller open-source models, we’ve significantly reduced costs while maintaining competitive quality.\n\nAnother innovative use case is TOBU, a product that allows users to attach memories to pictures through a conversational AI. This AI interacts with users about their experiences and the context of their photos, creating a personalized memory assistant.\n\n## What are some of the most significant challenges you’ve encountered in implementing these projects and what have you learned from it?\n\nCost remains a significant challenge when scaling AI solutions. While development costs might be manageable during the initial phase, launching a product to thousands of users can become prohibitively expensive. This has driven a deeper investigation into using challenger models like Mistral and Llama to balance cost and performance effectively.\n\nExpertise within partner companies also plays a crucial role in the successful deployment of AI. Our consulting approach involves delivering IP and production-ready AI engines while navigating challenges such as bounding AI use cases to prevent liability and ensuring that AI solutions remain within desired parameters.\n\n## How do you assess state and federal regulations, security and the privacy?\n\nAs we consume more information through screens, the realm of AI expands. It’s essential to control this growth thoughtfully, ensuring AI remains a tool for good. The current phase of AI development involves creating tools to harness the full potential of these models, akin to refining raw ore.\n\nTools like Lang Chain, funded by Sequoia, exemplify the innovation in this space. These tools help solve bigger problems by enabling seamless interaction with large language models. Personalization remains a key focus, making AI more accessible and tailored to individual needs.\n\nIn conclusion, the landscape of AI is evolving rapidly, with companies seeking to balance opportunities and risks. Through careful analysis, cost-effective solutions, and innovative use cases, businesses can harness the power of generative AI to drive efficiency and personalization in unprecedented ways.\n","slug":"post1"},{"frontmatter":{"title":"A Whale of a Tale: The Size-Matters Misconception For Generative AI","description":"meta description","date":"2023-04-04T00:00:00.000Z","image":"/images/posts/post-2.jpg","categories":["Developers"],"authors":["Forbes"],"tags":["Developers"],"draft":false},"content":"\nIn this new age of generative AI, everyone has made a major assumption for which a pressing question has emerged. You can see this manifesting in certain nerdy corners of social media.\n\nThis screenshot of Reddit and Twitter posts shows the rising curiosity about the effectiveness of small, open-source models versus their large, proprietary counterparts. Indeed, in this noisy market, there is widespread confusion and curiosity surrounding this topic. The narrative that “bigger is inherently better” is about to be challenged.\n\n![_Is bigger necessarily better when it comes to AI models? Maybe not.](/images/posts/post-2.1.png)\n_Is bigger necessarily better when it comes to AI models? Maybe not._\n\nWell, along with my amazing colleagues at the University of Michigan and Jaseci Labs, we’ve delved into this very question in a rigorous and scholarly way. We’ve produced the first academic paper that addresses the debate head-on, to be presented in the prestigious ISPASS 2024 proceedings.\n\nOur findings are not just surprising; they are a call to rethink what we know about the size of AI models we should be relying on in production and commercial use cases, and the efficiency we can achieve.\n\n## Two Major AI Contenders\n\nSo, let’s talk about the two contenders, the Large Language Models (GPT4 and friends) vs the Small Language Models. Open AI has published GPT4 models that are at least 540 gigabytes, while the small and open-source models we study in the paper are around three gigabytes. That’s around 200 times smaller.\n\nTo illustrate the comparison, imagine GPT-4 as the blue whale, the largest animal on the planet, weighing up to about 200 tons. Now, contrast this with a housefly, a creature so small it’s easy to overlook, weighing in at a mere 12 milligrams.\n\nThese houseflies would be our models like LLaMA-7b quantized, Mistral-7b quantized, and Starling-LM-7b quantized — smaller, open-source alternatives poised to challenge the notion that bigger always means better. This comparison represents the difference in scale between the models we study in the paper.\n\nThe core discovery in the paper is simple: the belief that one must wield a GPT-4-sized model to achieve significant results is a myth.\n\n## Our Approach\n\nOur research was conducted with open and quantized models and gpt4 itself. Our investigation was centered around a case study with the commercial Myca.ai product, a productivity tool enhanced by AI to deliver personalized pep talks based on your productivity. The results, as detailed in our paper, are nothing short of shocking even to us.\n\nWe asked three simple questions. Can end users tell a quality loss in response when using the housefly models? How much faster are the AI responses with the smaller open models? And how much cheaper is it?\n\n## On Quality\n\n![Response quality of GPT-4 and SLMs as rated by human reviewers.](/images/posts/post-2.2.png)\n_Response quality of GPT-4 and SLMs as rated by human reviewers._\n\nWhen participants were subjected to a blind test comparing the output of large proprietary models against that of smaller, open-source models, the results were revelatory. Like the famed Pepsi/Coke taste tests, users were hard-pressed to discern which model produced the output. Indeed, much of the time, OpenAI’s GPT4 was not selected or scored very poorly. GPT4 was selected as the better output only around half the time than an SLM. For many (perhaps most) practical product use cases, SLMs do not only as well as sometimes even better than generalized proprietary LLMs. This result underscored the competency of smaller models in delivering quality content indistinguishable from their larger counterparts.\n\n## On Speed\n\nFurther analysis revealed that these smaller models are up to 10 times faster than GPT-4 on our own machines in an AWS cluster and offer greater reliability. The latency of response was consistent all day long.\n\nAnd Myca.ai didn’t suffer from the outages that OpenAI has become known for. Given that our housefly models are not tethered to the operational integrity of any single provider, they remain unaffected by these outages that can impact any of the larger, proprietary models.\n\n## On Cost\n\nPerhaps most compelling is the cost advantage. Our research indicates that deploying small, open models can be anywhere from five to 23 times cheaper than relying on a model like GPT-4. This range represents a worst-case to best-case scenario, highlighting the substantial financial benefits that come with adopting smaller models.\n\n## The Groundbreaking Insight\n\nWhen you opt for smaller, more accessible models, you not only gain control but also empower yourself with the ability to tailor the technology to your needs. Businesses, for example, can take these open-source models and adapt them, even going as far as training them in-house, without the prohibitive costs associated with larger models.\n\nOur findings invite a paradigm shift in how we approach the development and deployment of AI models. The evidence is clear: smaller, open-source models not only stand toe-to-toe with their gargantuan counterparts in terms of intelligence and capability but also offer critical advantages.\n\nIndeed, Jaseci Labs is now helping businesses tailor their own small models for game-changing product use cases, leading to what may be a major description of the OpenAIs and Anthropics of the world.\n\nWe encourage you to delve into the peer-reviewed analysis presented in our paper. Let the truth behind this rigorous analysis guide your decisions as you navigate the future of AI, and consider how embracing smaller models could not only enhance your technological endeavors but also democratize access to this groundbreaking field.\n\nThis article was originally posted on Forbes.com, click the link below to read the complete article.\n\n[Read the full article on Forbes](https://www.forbes.com/sites/forbesbooksauthors/2024/03/21/a-whale-of-a-tale-the-size-matters-misconception-for-generative-ai/?sh=40121c8c581a)\n","slug":"post2"},{"frontmatter":{"title":"Can Tiny Titans Take On The Giants in Generative AI? How Small Language Models Are Matching Up to Large Language Models.","description":"meta description","date":"2023-04-04T00:00:00.000Z","image":"/images/posts/post-3.jpg","categories":["Developers"],"authors":["Forbes"],"tags":["Developers"],"draft":false},"content":"\nWith the rapid evolution of large language models (LLMs), the world has begun to rely on the APIs of managed AI models such as OpenAI’s GPT-4. Its cutting-edge capabilities and developer-friendly interface have gained a large fan base not only in academia but also in the industry-wide as well. As every rose has its thorn, there are some downsides to those proprietary APIs despite all the benefits they bring to the table. Performance reliability, uptime predictability, and cost are some of them. At the same time, a flurry of open-source small language models (SLMs) has been made available for commercial use.\nSo, here we face the ultimate question,\n\n## Is GPT-4 really worth it?\n\nor can those open-source SLMs replace proprietary LLMs?\nBut before we dive into this question, another problem comes to play.\n\n### How are we going to evaluate proprietary LLM vs open-source SLM?\n\nIn the paper, the authors introduce a new toolset, SLaM to evaluate the performance of SLM vs LLM across a wide range of metrics.\n\nSLaM is a system that facilitates the process of hosting and evaluating language models on the AWS cloud. It works by downloading models from the Hugging Face repository and setting them up for experiments. To evaluate the quality of these models, SLaM uses both human and automated methods. For human evaluation, SLaM provides a user interface (UI) where humans can rate model responses without knowing which model generated which response. For automated evaluation, SLaM uses a Similarity Scorer and GPT-4-based scoring to assess response quality based on similarity metrics. In addition to this, SLaM performs automatic performance evaluations by measuring query latency over time.\n\nWhen investigating this feature in a real-world product, the authors have considered a ‘PEP-TALK’ feature in a task management and productivity application called ‘Myca’. When users log into the app at the start of their day, it gives them a positive message tailored to their previous day’s achievements, plans, and overall progress toward their goals. The ‘PEP-TALK’ feature combines the user’s past activities and plans into a prompt, fed into a language model, which generates a motivational response displayed to the user.\n\nSo, this [paper](https://arxiv.org/pdf/2312.14972) discusses four questions related to moving from proprietary LLMs to self-hosted SLMs.\n\n1. Is the quality of SLMs good enough for users?\n2. How well can AI-assisted tooling automate the process of identifying SLM alternatives?\n3. What are the latency implications of self-hosted SLMs in a utility-based cloud environment?\n4. What are the cost tradeoffs of open-source SLMs compared to proprietary LLM APIs?\n\nIn this article we are going to talk about the quality of the content generated by SLMs.\nThis box distribution depicts the performances of 9 SLMs all together with their 29 quantized models which were reviewed by humans along with a proprietary LLM.\n\nThis shows that some smaller language models (SLMs) can create responses just as good as, or even better than, the larger models made by OpenAI. Especially, the smaller, optimized versions of these models, called quantized models, are doing really well, which is great for using them in real-world applications because they take up less space. Most of the SLMs tested produce responses that are almost as good as the best models, indicating that the quality of their responses is quite similar to that of OpenAI’s models. However, a few specific models, namely the orca2:7b (both base and optimized versions) and stablelm-zephyr:3b-q3, didn’t perform as well and had noticeably poorer response quality compared to others.\n\n### So, SLMs can indeed produce good content just as good as proprietary LLMs\n\nbut the debate on whether they can replace LLMs continues. And we can’t come to a final decision without the answers to other three questions.\n","slug":"post3"},{"frontmatter":{"title":"What’s In Store For The Next Generation Of AI? The Jaseci Perspective","description":"meta description","date":"2023-04-04T00:00:00.000Z","image":"/images/posts/post-4.jpg","categories":["AI + Business"],"authors":["Forbes"],"tags":["AI + Business"],"draft":false},"content":"\nBehind every great application, game, and digital experience are the endless lines of code produced in one of the popular programming languages. You know, the Pythons, JavaScripts, Javas—the list goes on.\n\nAnd the more you work with these popular programming languages, the quicker you discover the true meaning of compromise. That’s not to say these languages aren’t great at what they do, because they are.  \n\nThis article was originally posted on Forbes.com, click the link below to read the complete article.\n\n[https://www.forbes.com/sites/forbesbooksauthors/2021/05/18/whats-in-store-for-the-next-generation-of-ai-the-jaseci-perspective/](https://www.forbes.com/sites/forbesbooksauthors/2021/05/18/whats-in-store-for-the-next-generation-of-ai-the-jaseci-perspective/){color:white}\n\n","slug":"post4"},{"frontmatter":{"title":"What Is Conversational AI? ZeroShot Bot CEO Jason Mars Explains","description":"meta description","date":"2023-04-04T00:00:00.000Z","image":"/images/posts/post-5.png","categories":["Developers"],"authors":["Nvidia"],"tags":["Developers"],"draft":false},"content":"\nEntrepreneur Jason Mars calls conversation our “first technology.”\n\nBefore humans invented the wheel, crafted a spear or tamed fire, we mastered the superpower of talking to one another.\n\nThat makes conversation an incredibly important tool.\n\nBut if you’ve dealt with the automated chatbots deployed by the customer service arms of just about any big organization lately — whether banks or airlines — you also know how hard it can be to get it right.\n\n[Deep learning AI](https://blogs.nvidia.com/blog/deep-learning-2/) and new techniques such as zero-shot learning promise to change that.\n\nOn this episode of NVIDIA’s [AI Podcast](blogs.nvidia.com/ai-podcast/), host Noah Kravitz — whose intelligence is anything but artificial — spoke with Mars about how the latest AI techniques intersect with the very ancient art of conversation.\n\nIn addition to being an entrepreneur and CEO of several startups, including Zero Shot Bot, Mars is an associate professor of computer science at the University of Michigan and the author of “Breaking Bots: Inventing a New Voice in the AI Revolution” (ForbesBooks, 2021).\n\nThis article was originally posted on nvidia.com, click the link below to read the complete article.\n\n[https://blogs.nvidia.com/blog/2022/04/27/what-is-conversational-ai-jason-mars/](https://blogs.nvidia.com/blog/2022/04/27/what-is-conversational-ai-jason-mars/)","slug":"post5"}]